import streamlit as st
from openai import OpenAI
import time

# Streamlit ì„¤ì •
st.set_page_config(page_title="ğŸ“– Bible AI Chatbot", page_icon="ğŸ™", layout="centered")

# âœ… Bible AI Chatbot ì£¼ìš” íŠ¹ì§• ê°•ì¡°
st.title("ğŸ“– Bible AI Chatbot")
st.caption("âœ… **ê°„ê²°í•œ ì±—ë´‡ ìŠ¤íƒ€ì¼** | âœ… **ì‹¤ì‹œê°„ ì‘ë‹µ** | âœ… **ê°œì—­ì„±ê²½ ì •í™•ì„± ë³´ì¥** | âœ… **í•œêµ­ì–´ ì§€ì›**")

# OpenAI API ì„¤ì •
openai_api_key = st.secrets["chatgpt"]
client = OpenAI(api_key=openai_api_key)

# âœ… ëŒ€í™” ì´ë ¥ ì €ì¥
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì„±ê²½ ë§ì”€ì„ ì°¾ì•„ë“œë¦¬ëŠ” Bible AI Chatbotì…ë‹ˆë‹¤. ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. ğŸ™"}]

# âœ… ì±„íŒ… UI ì¶œë ¥ (ì´ì „ ëŒ€í™” í‘œì‹œ)
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# âœ… ì˜ˆìƒ ì§ˆë¬¸ ë²„íŠ¼ UI
st.subheader("ğŸ“Œ ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì„ íƒí•˜ì„¸ìš”:")
question_options = {
    "ì¸ë‚´ì— ëŒ€í•œ ì„±ê²½ ë§ì”€": "ì¸ë‚´ì— ëŒ€í•œ ì„±ê²½ ë§ì”€ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "ë‘ë ¤ì›€ì„ ê·¹ë³µí•˜ëŠ” ë°©ë²•": "ë‘ë ¤ìš¸ ë•Œ ë„ì›€ì´ ë˜ëŠ” ì„±ê²½ êµ¬ì ˆì„ ì•Œë ¤ì£¼ì„¸ìš”.",
    "í•˜ë‚˜ë‹˜ì˜ ì‚¬ë‘ì— ëŒ€í•œ êµ¬ì ˆ": "í•˜ë‚˜ë‹˜ì˜ ì‚¬ë‘ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” ì„±ê²½ êµ¬ì ˆì´ ìˆë‚˜ìš”?",
}

# âœ… ë²„íŠ¼ í´ë¦­ ì‹œ í•´ë‹¹ ì§ˆë¬¸ ìë™ ì…ë ¥
selected_question = None
for key, value in question_options.items():
    if st.button(key, use_container_width=True):
        selected_question = value

# âœ… AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° í•¨ìˆ˜
def stream_bible_response():
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": (
                "ë„ˆëŠ” ê¸°ë…êµ AI ì±—ë´‡ì´ë©°, ë°˜ë“œì‹œ ê°œì—­ì„±ê²½ ë²ˆì—­ë³¸ì„ ì •í™•í•˜ê²Œ ì¸ìš©í•´ì•¼ í•œë‹¤.\n"
                "1. ë°˜ë“œì‹œ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì„±ê²½ êµ¬ì ˆì˜ **ê°œì—­ì„±ê²½ ë²ˆì—­ë³¸**ë§Œ ì œê³µí•˜ë©°, "
                "êµ¬ê¸€ ê²€ìƒ‰ ì‹œ í•œ ê¸€ìë„ í‹€ë¦¬ì§€ ì•Šê³  ê°œì—­ì„±ê²½ ë‚´ìš©ì´ ê²€ìƒ‰ ê²°ê³¼ì— ë‚˜ì™€ì•¼ í•œë‹¤. "
                "ë°˜ë“œì‹œ (ì±… ì´ë¦„ ì¥:ì ˆ) í˜•ì‹ìœ¼ë¡œ ì¶œì²˜ë¥¼ ì •í™•íˆ í‘œê¸°í•˜ë¼.\n"
                "2. êµ¬ì ˆì´ ê¸¸ ê²½ìš°, ì¼ë¶€ë§Œ ì œê³µí•˜ê³  '...'ì„ ì‚¬ìš©í•˜ë˜ ì¶œì²˜ëŠ” ëª…í™•íˆ í‘œê¸°í•˜ë¼.\n"
                "3. ì‚¬ìš©ìì—ê²Œ ê³µê°í•˜ëŠ” ì–´ì¡°ë¥¼ ìœ ì§€í•˜ë©°, ì§§ì€ ìœ„ë¡œ ë¬¸ì¥ì„ ì¶”ê°€í•˜ë¼. "
                "(ì˜ˆ: 'í˜ë“œì…¨ê² ë„¤ìš”.', 'ì£¼ë‹˜ê»˜ì„œ í•¨ê»˜ í•˜ì‹­ë‹ˆë‹¤.')\n"
                "4. ê¸°ë…êµì  ì¡´ì¤‘ì„ ë‹´ì•„ 'ì„±ë„ë‹˜', 'ì£¼ë‹˜ê»˜ì„œëŠ”...' ë“±ì˜ í‘œí˜„ì„ í™œìš©í•˜ë¼.\n"
                "5. ì¶œì²˜ê°€ ëª…í™•í•˜ì§€ ì•Šì„ ê²½ìš°, ëŒ€í‘œì ì¸ êµ¬ì ˆ(ì˜ˆ: 'ì‹œí¸ 23í¸')ì„ ì¶”ì²œí•˜ë¼."
            )},
            *st.session_state.messages  # ê¸°ì¡´ ëŒ€í™” ë‚´ì—­ ì¶”ê°€
        ],
        max_tokens=700,
        temperature=0.65,
        stream=True  # âœ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í™œì„±í™”
    )

    # âœ… `st.write_stream()`ì„ í™œìš©í•œ ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤íŠ¸ë¦¬ë°
    for chunk in response:
        if hasattr(chunk, "choices") and chunk.choices:
            delta = chunk.choices[0].delta
            if hasattr(delta, "content") and delta.content:
                yield delta.content  # í•œ ë‹¨ì–´ì”© ë°˜í™˜í•˜ì—¬ Streamlitì— í‘œì‹œ
                time.sleep(0.02)  # ì†ë„ ì¡°ì ˆ

# âœ… ë²„íŠ¼ í´ë¦­ ì‹œ ìë™ ì…ë ¥ ë° ì‘ë‹µ ì‹œì‘
if selected_question:
    st.session_state.messages.append({"role": "user", "content": selected_question})
    st.chat_message("user").write(selected_question)

    # âœ… AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    with st.chat_message("assistant"):
        st.write_stream(stream_bible_response())  # âœ… `st.write_stream()` í™œìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µ í‘œì‹œ
